import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

const app = express();
const PORT = process.env.PORT || 3002;

// Middleware
app.use(cors());
app.use(express.json({ limit: '10mb' }));

// Basic logging middleware
app.use((req, res, next) => {
  console.log(`${new Date().toISOString()} - ${req.method} ${req.path}`);
  next();
});

// Health check endpoint
app.get('/api/health', (req, res) => {
  res.json({ 
    success: true, 
    message: 'Server is running',
    timestamp: new Date().toISOString(),
    apiKeyConfigured: !!process.env.GEMINI_API_KEY
  });
});

// Gemini API proxy endpoint
app.post('/api/gemini', async (req, res) => {
  try {
    const { prompt } = req.body;

    if (!prompt) {
      return res.status(400).json({
        success: false,
        error: 'Prompt is required'
      });
    }

    // Check if API key is configured
    console.log('Checking API key...', process.env.GEMINI_API_KEY ? 'Found' : 'Not found');
    if (!process.env.GEMINI_API_KEY) {
      console.warn('GEMINI_API_KEY not found. Using mock response.');
      
      // Return mock response for development
      const mockResponse = {
        success: true,
        data: {
          text: `Mock response for: "${prompt}". This is a placeholder response since no Gemini API key is configured. The actual response would be generated by Gemini AI based on your prompt.`,
          confidence: 0.8,
          suggestions: ["This is a mock response", "Configure GEMINI_API_KEY for real responses"]
        }
      };
      
      return res.json(mockResponse);
    }

    // Prepare the request to Gemini API
    const geminiRequest = {
      contents: [
        {
          parts: [
            {
              text: prompt
            }
          ]
        }
      ],
      generationConfig: {
        temperature: 0.7,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 4096,
      },
      safetySettings: [
        {
          category: "HARM_CATEGORY_HARASSMENT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_HATE_SPEECH",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_DANGEROUS_CONTENT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        }
      ]
    };

    // Make request to Gemini API - Using Gemini 2.5 Flash with fallbacks
    const modelOptions = [
      'gemini-2.5-flash',
      'gemini-2.5-flash-lite', 
      'gemini-1.5-flash',
      'gemini-1.5-pro'
    ];
    
    let geminiResponse;
    let lastError;
    
    for (const model of modelOptions) {
      try {
        const geminiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${process.env.GEMINI_API_KEY}`;
        
        const response = await fetch(geminiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(geminiRequest)
        });

        if (response.ok) {
          geminiResponse = await response.json();
          console.log(`Successfully used model: ${model}`);
          console.log('Gemini response:', JSON.stringify(geminiResponse, null, 2));
          break;
        } else {
          const errorText = await response.text();
          console.log(`Model ${model} failed with status ${response.status}: ${errorText}`);
          lastError = { status: response.status, text: errorText };
        }
      } catch (error) {
        console.log(`Model ${model} failed with error:`, error);
        lastError = error;
      }
    }
    
    if (!geminiResponse) {
      console.error('All models failed. Last error:', lastError);
      
      // Check if API key is suspended and provide appropriate fallback
      const isSuspended = lastError?.text?.includes('suspended') || lastError?.text?.includes('CONSUMER_SUSPENDED');
      
      if (isSuspended) {
        console.warn('API key is suspended. Falling back to mock responses.');
        return res.json({
          success: true,
          data: {
            text: `[Mock Response - API Key Suspended] Regarding "${prompt}": This is a simulated AI response. The actual Gemini API key has been suspended, so this is a placeholder response that would normally be generated by Gemini 2.5 Flash AI.`,
            confidence: 0.7,
            suggestions: ["API key suspended", "Using mock responses", "Check Google AI Studio for API key status"]
          }
        });
      }
      
      return res.status(500).json({
        success: false,
        error: `All Gemini models failed. Please check API key status.`,
        details: lastError
      });
    }
    
    // Extract text from Gemini response
    let responseText = 'No response generated';
    console.log('Processing response for text extraction...');
    
    if (geminiResponse.candidates && geminiResponse.candidates.length > 0) {
      const candidate = geminiResponse.candidates[0];
      console.log('Candidate:', JSON.stringify(candidate, null, 2));
      
      // Handle different response structures for different Gemini models
      if (candidate.content) {
        if (candidate.content.parts && candidate.content.parts.length > 0) {
          // Standard response structure (Gemini 1.5)
          responseText = candidate.content.parts[0].text;
        } else if (candidate.content.text) {
          // Alternative structure
          responseText = candidate.content.text;
        } else if (typeof candidate.content === 'string') {
          // Direct string content
          responseText = candidate.content;
        }
      } else if (candidate.text) {
        // Direct text property
        responseText = candidate.text;
      }
      
      // Handle cases where content might be in thoughts (Gemini 2.5 thinking models)
      if (responseText === 'No response generated' && geminiResponse.usageMetadata?.thoughtsTokenCount) {
        responseText = `I processed your question about "${prompt}" but the response was generated as internal reasoning. This appears to be a thinking model response. The question was processed successfully.`;
      }
    }

    // Return formatted response
    res.json({
      success: true,
      data: {
        text: responseText,
        confidence: 0.9, // Gemini doesn't return confidence, so we use a default
        suggestions: []
      }
    });

  } catch (error) {
    console.error('Server error:', error);
    
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Error handling middleware
app.use((err: Error, req: express.Request, res: express.Response) => {
  console.error('Unhandled error:', err);
  res.status(500).json({
    success: false,
    error: 'Internal server error'
  });
});

// 404 handler
app.use((req, res) => {
  res.status(404).json({
    success: false,
    error: 'Endpoint not found'
  });
});

// Start server
app.listen(PORT, () => {
  console.log(`🚀 Server running on http://localhost:${PORT}`);
  console.log(`📡 API endpoint: http://localhost:${PORT}/api/gemini`);
  console.log(`🏥 Health check: http://localhost:${PORT}/api/health`);
  
  if (!process.env.GEMINI_API_KEY) {
    console.log('⚠️  GEMINI_API_KEY not found - using mock responses');
    console.log('💡 Add your Gemini API key to .env file for real AI responses');
  } else {
    console.log('✅ Gemini API key configured');
  }
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('🛑 SIGTERM received, shutting down gracefully');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('🛑 SIGINT received, shutting down gracefully');
  process.exit(0);
});